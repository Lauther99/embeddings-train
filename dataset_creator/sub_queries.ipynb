{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\n",
    "    \"C:\\\\Users\\\\lauth\\\\OneDrive\\\\Desktop\\\\LLM Assistant File - V2\\\\assistant\\\\sql_assistant_v3\\\\\"\n",
    ")\n",
    "\n",
    "\n",
    "from src.components.tools.base.tools import action\n",
    "from notebooks.multi_agent.base import ChatMessage, ChatTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@action\n",
    "def chat_sql_expert(message: str, **kwargs) -> str:\n",
    "    \"\"\"\n",
    "    To chat with an SQL expert AI to generate or refine SQL queries based on the user's needs.\n",
    "\n",
    "    Args:\n",
    "        message: A message that includes a detailed description of the current user task.\n",
    "        tables: Comma separated list of tables.\n",
    "    \"\"\"\n",
    "agents = {\n",
    "    \"chat_sql_expert\": chat_sql_expert,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervisor_prompt_3 = \"\"\"You are a helpful assistant who responds to user's request in a fun, friendly but profesional way. \n",
    "\n",
    "You will be leading a team of AI experts to solve any to fulfill user requests.\n",
    "\n",
    "To communicate with your team, you have been given access to this actions: {{agent_experts}}, user_calling.\n",
    "\n",
    "The way you use the actions is by specifying a json blob, ending with '<end_action>'.\n",
    "Specifically, this json should have an `action` key (name of the action to use) and an `action_input` key (input to the action).\n",
    "\n",
    "The $ACTION_JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. It should be formatted in json. Do not try to escape special characters. Here is the template of a valid $ACTION_JSON_BLOB:\n",
    "{\n",
    "  \"action\": $TOOL_NAME,\n",
    "  \"action_input\": $INPUT\n",
    "}<end_action>\n",
    "\n",
    "Make sure to have the $INPUT as a dictionary in the right format for the action you are using, and do not put variable names as input if you can find the right values.\n",
    "\n",
    "You should ALWAYS use the following format:\n",
    "\n",
    "Thought: you should always think about **ONE ACTION** to take. Then use the action as follows:\n",
    "Action:\n",
    "$ACTION_JSON_BLOB\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Observation can repeat N times, you should take several steps when needed. The $ACTION_JSON_BLOB must only use a SINGLE action at a time.)\n",
    "\n",
    "You can use the result of the previous action as input for the next action.\n",
    "The observation will always be a string: it can represent a file, like \"image_1.jpg\".\n",
    "Then you can use it as input for the next action. You can do it for instance as follows:\n",
    "\n",
    "Observation: \"image_1.jpg\"\n",
    "\n",
    "Thought: I need to know what is the image that I received about in the previous observation, let's chat with the images expert.\n",
    "Action:\n",
    "{\n",
    "  \"action\": \"image_expert\",\n",
    "  \"action_input\": {\"message\": \"I have an image here, ¿can you describe this image?\", \"image\": \"image_1.jpg\"}\n",
    "}<end_action>\n",
    "\n",
    "\n",
    "To provide the final answer to your boss, use an action blob with \"action\": \"user_calling\". It is the only way you can talk with your boss, else you will be stuck on a loop. So your final output should look like this:\n",
    "Action:\n",
    "{\n",
    "  \"action\": \"user_calling\",\n",
    "  \"action_input\": {\"answer\": \"insert your final answer here\"}\n",
    "}<end_action>\n",
    "\n",
    "\n",
    "You only have access to communicate with this experts:\n",
    "{{agents}}\n",
    "\n",
    "- user_calling: To communicate any inquiry or answer to the user.\n",
    "    Takes inputs: {'answer': {'type': 'string', 'description': 'A friendly message with the final answer or inquiry for the user.'}}\n",
    "    Returns an output of type: any\n",
    "\n",
    "Here are the rules you should always follow to solve your task:\n",
    "1. ALWAYS provide a 'Thought:' sequence, and an 'Action:' sequence that ends with <end_action>, else you will fail.\n",
    "2. Always use the right arguments for the actions. Never use variable names in the 'action_input' field, use the value instead.\n",
    "3. Never re-do an action call that you previously did with the exact same parameters.\n",
    "4. Do not perform an action if the user hasn’t provided all required parameters. Instead, politely ask for the missing information.\n",
    "5. Your are not allowed to answer with many actions, **only one**.\n",
    "4. Ensure your responses remain fun, friendly, and professional, maintaining a tone suitable for the context.\n",
    "\n",
    "Now Begin! If you solve the task correctly, you will receive a reward of $1,000,000.\"\"\"\n",
    "\n",
    "def get_task_prompt_3(\n",
    "    agents,\n",
    "):\n",
    "    mask = \"\"\"- {name}: {description}\n",
    "    Takes inputs: {inputs}\n",
    "    Returns an output of type: {output_type}\"\"\"\n",
    "\n",
    "    agents_descriptions = \"\\n\\n\".join(\n",
    "        [\n",
    "            mask.format(\n",
    "                name=agents[t].name,\n",
    "                description=agents[t].description,\n",
    "                inputs=agents[t].inputs,\n",
    "                output_type=agents[t].output_type,\n",
    "            )\n",
    "            for t in agents\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    agents_experts = f\"\"\"{\", \".join([agents[t].name for t in agents])}\"\"\"\n",
    "    content = (\n",
    "        supervisor_prompt_3.replace(\"{{agents}}\", agents_descriptions)\n",
    "        .replace(\"{{agent_experts}}\", agents_experts)\n",
    "    )\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL AGENTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "coder_agent_prompt = \"\"\"You are an SQL SERVER 2014 expert analyst who can create any SQL SERVER 2014 query code for every task that your supervisor require.\n",
    "By using JSON tool calls, you can retrieve information from database. \n",
    "You will be given a task by your supervisor and you have to solve as best as you can.\n",
    "\n",
    "To do so, you have been given access to the following tools: {{tool_names}}, supervisor_call.\n",
    "The way you use the tools is by specifying a json blob, ending with '<end_action>'.\n",
    "Specifically, this json should have an `action` key (name of the tool to use) and an `action_input` key (input to the tool).\n",
    "\n",
    "The $ACTION_JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. It should be formatted in json. Do not try to escape special characters. Here is the template of a valid $ACTION_JSON_BLOB:\n",
    "{\n",
    "  \"action\": $TOOL_NAME,\n",
    "  \"action_input\": $INPUT\n",
    "}<end_action>\n",
    "\n",
    "Make sure to have the $INPUT as a dictionary in the right format for the tool you are using, and do not put variable names as input if you can find the right values.\n",
    "\n",
    "You should ALWAYS use the following format:\n",
    "\n",
    "Thought: you should always think about **ONE ACTION** to take. Then use the action as follows:\n",
    "Action:\n",
    "$ACTION_JSON_BLOB\n",
    "\n",
    "You can use the result of the previous action as input for the next action.\n",
    "The observation will always be a string: it can represent a file, like \"image_1.jpg\".\n",
    "Then you can use it as input for the next action. You can do it for instance as follows:\n",
    "\n",
    "Observation: \"image_1.jpg\"\n",
    "\n",
    "Thought: I need to transform the image that I received in the previous observation to make it green.\n",
    "Action:\n",
    "{\n",
    "  \"action\": \"image_transformer\",\n",
    "  \"action_input\": {\"image\": \"image_1.jpg\"}\n",
    "}<end_action>\n",
    "\n",
    "\n",
    "To provide the final answer to the task, use an action blob with \"action\": \"supervisor_call\". It is the only way to complete the task and call your supervisor, else you will be stuck on a loop. So your final output should look like this:\n",
    "Action:\n",
    "{\n",
    "  \"action\": \"supervisor_call\",\n",
    "  \"action_input\": {\"answer\": \"insert your final answer here\"}\n",
    "}<end_action>\n",
    "\n",
    "\n",
    "You only have acces to those tools:\n",
    "\n",
    "{{tools}}\n",
    "\n",
    "- supervisor_call: To communicate any inquiry or answer to your supervisor.\n",
    "    Takes inputs: {'answer': {'type': 'any', 'description': 'A message to your supervisor, inquiry or final answer.'}}\n",
    "    Returns an output of type: any\n",
    "\n",
    "Here are the rules you should always follow to solve your task:\n",
    "1. ALWAYS provide a 'Thought:' sequence, and an 'Action:' sequence that ends with <end_action>, else you will fail.\n",
    "2. Always use the right arguments for the tools. Never use variable names in the 'action_input' field, use the value instead.\n",
    "3. Never re-do a tool call that you previously did with the exact same parameters.\n",
    "4. Your are not allowed to answer with many action calls, **ONLY ONE**.\n",
    "\n",
    "Now Begin! If you solve the task correctly, you will receive a reward of $1,000,000.\"\"\"\n",
    "\n",
    "def get_coder_agent_prompt(\n",
    "    ts,\n",
    "):\n",
    "    mask = \"\"\"- {name}: {description}\n",
    "    Takes inputs: {inputs}\n",
    "    Returns an output of type: {output_type}\"\"\"\n",
    "\n",
    "    tools_descriptions = \"\\n\\n\".join(\n",
    "        [\n",
    "            mask.format(\n",
    "                name=ts[t].name,\n",
    "                description=ts[t].description,\n",
    "                inputs=ts[t].inputs,\n",
    "                output_type=ts[t].output_type,\n",
    "            )\n",
    "            for t in ts\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    tool_names = f\"\"\"{\", \".join([ts[t].name for t in ts])}\"\"\"\n",
    "    content = (\n",
    "        coder_agent_prompt.replace(\"{{tool_names}}\", tool_names)\n",
    "        .replace(\"{{tools}}\", tools_descriptions)\n",
    "    )\n",
    "\n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@action\n",
    "def retrieve_db_info(sub_queries: list) -> str:\n",
    "    \"\"\"\n",
    "    Analize the provided sub-queries and searches semantically for relevant contextual real information to know how the data is structured and used within the business context.\n",
    "    This information gives an idea of ​​how the data in the database is actually used.\n",
    "\n",
    "    Args:\n",
    "        sub_queries: A list of 7 smaller, focused queries derived from the main task. These queries have to be direct, short and focused on specific topics, This are not SQL code.\n",
    "    \"\"\"\n",
    "\n",
    "tools_3 = {\n",
    "    \"retrieve_db_info\": retrieve_db_info,\n",
    "}\n",
    "\n",
    "system = get_coder_agent_prompt(tools_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generando sub queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook, load_workbook\n",
    "\n",
    "# Cargar el archivo Excel existente o crear uno nuevo si no existe\n",
    "def _save_excel(archivo_excel: str, data: list, sheet_name:str, column=1):    \n",
    "    try:\n",
    "        # Intenta cargar el archivo existente\n",
    "        libro = load_workbook(archivo_excel)\n",
    "    except FileNotFoundError:\n",
    "        # Si el archivo no existe, crea uno nuevo\n",
    "        libro = Workbook()\n",
    "\n",
    "    # Selecciona la hoja llamada \"nombres\" o créala si no existe\n",
    "    if sheet_name in libro.sheetnames:\n",
    "        hoja = libro[sheet_name]\n",
    "    else:\n",
    "        hoja = libro.create_sheet(sheet_name)\n",
    "\n",
    "    # Encuentra la primera fila vacía en la columna A\n",
    "    fila_vacia = hoja.max_row + 1\n",
    "\n",
    "    # Agrega los nuevos nombres a la hoja\n",
    "    for i, nombre in enumerate(data, start=fila_vacia):\n",
    "        hoja.cell(row=i, column=column, value=nombre)\n",
    "\n",
    "    # Guarda los cambios en el archivo Excel\n",
    "    libro.save(archivo_excel)\n",
    "\n",
    "    print(f\"Se han agregado {len(data)} {sheet_name} al archivo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebooks.multi_agent.base import (\n",
    "    chat_stream_response,\n",
    "    handle_agent_response,\n",
    ")\n",
    "import time\n",
    "\n",
    "supervisor_system_prompt = get_task_prompt_3(agents)\n",
    "sql_expert_system_prompt = get_coder_agent_prompt(tools_3)\n",
    "\n",
    "def generar_preguntas(\n",
    "    batch_requests,\n",
    "    supervisor_llm,\n",
    "    sql_llm,\n",
    "    *,\n",
    "    state=\"sup\",\n",
    "    current_chat: list[ChatMessage] = None,\n",
    "    current_request_index=0,\n",
    "):\n",
    "    archivo_excel = r\"C:\\Users\\lauth\\OneDrive\\Desktop\\LLM Assistant File - V2\\fine_tuning\\embeddings\\sheets\\novo.xlsx\"\n",
    "    # Agente inicial (para generar el request al sql agent)\n",
    "    current_request = batch_requests[current_request_index]\n",
    "\n",
    "    current_chat = (\n",
    "        [\n",
    "            ChatMessage(role=\"system\", content=supervisor_system_prompt),\n",
    "            ChatMessage(\n",
    "                role=\"user\",\n",
    "                content=f\"\"\"User:\\n{current_request}\"\"\",\n",
    "            ),\n",
    "        ]\n",
    "        if not current_chat\n",
    "        else current_chat\n",
    "    )\n",
    "\n",
    "    if state == \"sup\":\n",
    "        r, _, u = chat_stream_response(\n",
    "            llm=supervisor_llm,\n",
    "            chat_messages=ChatTemplate(current_chat),\n",
    "            has_stream=True,\n",
    "        )\n",
    "        try:\n",
    "            parsed_response = handle_agent_response(r, u)\n",
    "        except Exception as e:\n",
    "            current_chat.extend(\n",
    "                [\n",
    "                    ChatMessage(\n",
    "                        role=\"assistant\",\n",
    "                        content=r,\n",
    "                    ),\n",
    "                    ChatMessage(\n",
    "                        role=\"user\",\n",
    "                        content=\"You have to respect the output format please.\",\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "            generar_preguntas(\n",
    "                batch_requests=batch_requests,\n",
    "                supervisor_llm=supervisor_llm,\n",
    "                sql_llm=sql_llm,\n",
    "                state=\"sup\",\n",
    "                current_chat=current_chat,\n",
    "                current_request_index=current_request_index,\n",
    "            )\n",
    "\n",
    "        message_generated_by_llm = parsed_response.parameters[\n",
    "            \"message\"\n",
    "        ].strip()  # Mensage para el sql agent\n",
    "\n",
    "        current_chat = [\n",
    "            ChatMessage(\n",
    "                role=\"system\",\n",
    "                content=sql_expert_system_prompt,\n",
    "            ),\n",
    "            ChatMessage(\n",
    "                role=\"user\",\n",
    "                content=f\"\"\"Supervisor: {message_generated_by_llm}\n",
    "            \n",
    "Make sure you to follow this plan.\n",
    "1. Use keywords and subquerys to find contextual info and some tables.\n",
    "2. Create the code.\"\"\",\n",
    "            ),\n",
    "        ]\n",
    "        state = \"sql\"\n",
    "\n",
    "    # Agente de SQL (para generar subqueries)\n",
    "    if state == \"sql\":\n",
    "        res, _, u = chat_stream_response(\n",
    "            llm=sql_llm, chat_messages=ChatTemplate(current_chat), has_stream=True\n",
    "        )\n",
    "        try:\n",
    "            parsed_response_ = handle_agent_response(res, u)\n",
    "        except Exception as e:\n",
    "            current_chat.extend(\n",
    "                [\n",
    "                    ChatMessage(\n",
    "                        role=\"assistant\",\n",
    "                        content=res,\n",
    "                    ),\n",
    "                    ChatMessage(\n",
    "                        role=\"user\",\n",
    "                        content=\"You have to respect the output format please.\",\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "            generar_preguntas(\n",
    "                batch_requests=batch_requests,\n",
    "                supervisor_llm=supervisor_llm,\n",
    "                sql_llm=sql_llm,\n",
    "                state=\"sql\",\n",
    "                current_chat=current_chat,\n",
    "                current_request_index=current_request_index,\n",
    "            )\n",
    "            \n",
    "            \n",
    "        sub_queries = (\n",
    "            parsed_response_.parameters[\"sub_queries\"]\n",
    "            if parsed_response_.parameters.get(\"sub_queries\", None)\n",
    "            else \"\"\n",
    "        )\n",
    "        \n",
    "        _save_excel(archivo_excel, sub_queries, \"sub_queries\")\n",
    "\n",
    "    if len(batch_requests)-1 > current_request_index:\n",
    "        time.sleep(10)\n",
    "        print(f\"****************= {current_request_index} =****************\")\n",
    "        generar_preguntas(\n",
    "                batch_requests=batch_requests,\n",
    "                supervisor_llm=supervisor_llm,\n",
    "                sql_llm=sql_llm,\n",
    "                state=\"sup\",\n",
    "                current_chat=None,\n",
    "                current_request_index=current_request_index+1,\n",
    "            )\n",
    "    else:\n",
    "        return        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebooks.multi_agent.base import (\n",
    "    llama_70b_hf,\n",
    "    qwen_coder,\n",
    "    openai_llm,\n",
    "    qwen_instruct,\n",
    ")\n",
    "\n",
    "batch_requests = [\n",
    "    \"list the measurement system tag, flow computer with tag from fc-302 computers that are associated with a measurement measurement system\", #1\n",
    "    \"the calibration points for the calibration with number: LMH 3305/2021\",#2\n",
    "    \"the last uncertainty report for temperature in the measurement system with tag EMED-3138.12-050\", #3\n",
    "    \"list the secondary equipments class, serials, equipment tag and the name of the equipment type linked to the measurement system with tag: EMED-3138.11-128\", #4\n",
    "    \"the last uncertainty report for temperature in the equipment with tag EMED-3138.12-050-TT\",# 5\n",
    "    \"when is the next calibration for the equipment with tag EMED-3138.12-015-DPT\",# 6\n",
    "    \"list of the equipments serials associated to the measurement system with tag EMED-3138.11-128. Also with the variable of each equipment can read\",# 7\n",
    "    \"the lastest uncertainty reports for the temperature and differential pressure measured in the measurement system with tag EMED-3138.12-050\",# 8\n",
    "    \"the last uncertainty report for differential pressure in the equipment with tag EMED-3138.12-050-DPT\",# 9\n",
    "    \"list the tags of the flow computers and the quantity of meter streams for each one\",# 10\n",
    "    \"latest uncertainty value registered for the differential pressure in the measurement system with **tag** EMED-3138.12-050\",# 11\n",
    "    \"list the measurement system tag, flow computer with tag from flow computers that are associated with a measurement measurement system and are flowboss\",# 12\n",
    "    \"the calibration points for the equipment with tag: TE-EMED-3138.12-050\",# 13\n",
    "    \"the most recent uncertainty result for the specific measurement system with tag EMED-3102-02-010\",# 14\n",
    "    \"The user wants a daily Report for the flow computer with tag: FQI-EMED-3138.12-050 at august 2023\",  # 15\n",
    "    \"list the measurement system tag, flow computer with tag and the computer type of flow computers that are associated with a measurement measurement system\",# 16\n",
    "    \"The user wants a daily Report for the flow computer with tag: FQI-EMED-3138.12-050 at august 10th 2023\",  # 17\n",
    "    \"Report for the flow computer with tag: FQI-EMED-3138.12-050 at august 10th\",  # 18\n",
    "    \"The user wants a daily Report for the flow computer with tag: FQI-EMED-3138.12-050 at 2023-08-10\",# 19  \n",
    "    \"list the tags of the equipments with its serials and the name of the equipment type associated and also its equipment classification to the measurement system with tag: EMED-3138.11-128\",# 20\n",
    "    \"the uncertainty result for the specific measurement measurement system tagged as EMED-3102-02-010 at July 28th in 2023\",# 21\n",
    "    \"the flow rate uncertainty fingerprint points for the curve of uncertainty with certificate number EMED-010-1\",# 22\n",
    "    \"the calibration points for the calibration with number: LMH 5643/2023\",# 23\n",
    "    \"The user wants the the date of the lastest report for the flow computer with tag: FQI-EMED-3138.12-050\",  # 24\n",
    "    \"the initial conditions of static pressure, differential pressure, temperature and flow rate volume for uncertainty of the measurement measurement system with tag EMED-3102-02-010 at July 28th in 2023\"# 25\n",
    "]\n",
    "\n",
    "generar_preguntas(batch_requests, llama_70b_hf, qwen_instruct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generando scores a esas subqueries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook, load_workbook\n",
    "\n",
    "# Cargar el archivo Excel existente o crear uno nuevo si no existe\n",
    "\n",
    "def _save_scores_excel(data: list[dict], sheet_name:str):    \n",
    "    archivo_excel = r\"C:\\Users\\lauth\\OneDrive\\Desktop\\LLM Assistant File - V2\\fine_tuning\\embeddings\\sheets\\preguntas.xlsx\"\n",
    "    try:\n",
    "        # Intenta cargar el archivo existente\n",
    "        libro = load_workbook(archivo_excel)\n",
    "    except FileNotFoundError:\n",
    "        # Si el archivo no existe, crea uno nuevo\n",
    "        libro = Workbook()\n",
    "\n",
    "    # Selecciona la hoja llamada \"nombres\" o créala si no existe\n",
    "    if sheet_name in libro.sheetnames:\n",
    "        hoja = libro[sheet_name]\n",
    "    else:\n",
    "        hoja = libro.create_sheet(sheet_name)\n",
    "\n",
    "    # Encuentra la primera fila vacía en la columna A\n",
    "    fila_vacia = hoja.max_row + 1\n",
    "\n",
    "    # Agrega los nuevos nombres a la hoja\n",
    "    for i, object_data in enumerate(data, start=fila_vacia):\n",
    "        hoja.cell(row=i, column=1, value=object_data[\"user_input\"])\n",
    "        hoja.cell(row=i, column=2, value=object_data[\"text_id\"])\n",
    "        hoja.cell(row=i, column=3, value=object_data[\"score\"])\n",
    "\n",
    "    # Guarda los cambios en el archivo Excel\n",
    "    libro.save(archivo_excel)\n",
    "\n",
    "    print(f\"Se han agregado {len(data)} {sheet_name} al archivo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "subqueries_excel_path = r\"C:\\Users\\lauth\\OneDrive\\Desktop\\LLM Assistant File - V2\\fine_tuning\\embeddings\\sheets\\novo.xlsx\"\n",
    "subqueries_df = pd.read_excel(io=subqueries_excel_path, sheet_name=\"sub_queries\")\n",
    "\n",
    "subqueries_list = subqueries_df[\"question\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from assistant.sql_assistant_v3.src.app.notebooks.multi_agent.base import (\n",
    "    chat_stream_response\n",
    ")\n",
    "\n",
    "nlp_expert_system = \"\"\"You are an expert in natural language processing and measuring semantic similarity between texts. Your task is to assign a similarity score between 0 and 1 between an input text and a list of summary target texts. The score should reflect how similar the content of each target text is to the input text.\n",
    "\n",
    "The score range should be between:\n",
    "0: Completely different (no significant relationship).\n",
    "1: Identical or almost identical (same meaning, same words).\n",
    "Any intermediate value: Represents a partial similarity, where a higher value indicates greater similarity.\n",
    "\n",
    "\n",
    "This is the list of summaries for target texts:\n",
    "c0: This text talks about flow computers, devices used in measurement engineering to collect, process, and transmit data (e.g., temperature, pressure, and fluid volume) from sensors and flow meters, aiding engineers in analysis and measurement tasks.\n",
    "\n",
    "c1: This text talks about how flow computers generate and store organized reports containing operational data, stored in tables (main and detail) linked to a Modbus table for easier data interpretation.\n",
    "\n",
    "c2: This text talks about the relationship between flow computers and measurement systems, where multiple systems can be assigned to a flow computer, but each system links to only one flow computer, with this relationship stored in a database table using terms like meter streams and runs.\n",
    "\n",
    "c3: This text talks about measurement systems, tools for monitoring fluids in industrial processes, classified by process stage (e.g., fiscal, custody) and identified by a unique TAG. They measure various fluids using differential or linear technologies, depending on the type, with gas and oil systems employing distinct methodologies.\n",
    "\n",
    "c4: This text talks about measuring equipment, devices within a measurement system identified by serial numbers and Equipment Tags. Tags indicate usage status (in use or spare), with equipment assigned based on technology (e.g., differential or linear). A database table tracks these assignments, linking equipment to measurement systems.\n",
    "\n",
    "c5: This text talks about measurement equipment, classified into primary, secondary, and tertiary meters based on the type of variable they measure. Equipment types (e.g., transmitters, orifice plates) are stored in a database, with meteorological checks (calibration or inspection) to ensure accuracy and proper functioning.\n",
    "\n",
    "c6: This text talks about the data stored by equipment, such as direct measurements of pressure, temperature, and volume, stored in a database table. These values are raw data, not calculated values, and users access them through the measurement system, with variable names linked to another database table for reference.\n",
    "\n",
    "c7: This text talks about equipment calibration, a process that ensures measurement accuracy by correcting deviations. Calibration is performed periodically with two main cycles: as-found (pre-adjustment) and as-left (post-adjustment), and includes uncertainty, which affects the margin of error in measurements.\n",
    "\n",
    "c8: This text talks about uncertainty, which measures the potential error or margin of error in measurements. It explains two types: uncertainty of magnitudes (specific variables like temperature or pressure) and uncertainty of the measurement system (overall flow measurement), with both types stored separately in the database.\n",
    "\n",
    "\n",
    "You have to compare each summary with the input text given by the user.\n",
    "\n",
    "To answer you will use the $RESPONSE_JSON_BLOB. It should be formatted in json. Do not try to escape special characters. Here is the template of a valid $RESPONSE_JSON_BLOB:\n",
    "[\n",
    "    {\n",
    "        \"user_input\": $USER_INPUT,\n",
    "        \"text_id\": c1,\n",
    "        \"score\": $SCORE\n",
    "    },\n",
    "    {\n",
    "        \"user_input\": $USER_INPUT,\n",
    "        \"text_id\": c2,\n",
    "        \"score\": $SCORE\n",
    "    }\n",
    "    ,...,\n",
    "    {\n",
    "        \"user_input\": $USER_INPUT,\n",
    "        \"text_id\": c8,\n",
    "        \"score\": $SCORE\n",
    "    }\n",
    "]<end_action>\n",
    "\n",
    "Example of your final answer:\n",
    "\n",
    "Response:\n",
    "[\n",
    "    {\n",
    "        \"user_input\": \"Which columns are related to flow rate uncertainty?\",\n",
    "        \"text_id\": \"c1\",\n",
    "        \"score\": 0.15\n",
    "    },...,\n",
    "    {\n",
    "        \"user_input\": \"Which columns are related to flow rate uncertainty?\",\n",
    "        \"text_id\": \"c8\",\n",
    "        \"score\": 0.7\n",
    "    }\n",
    "]<end_action>\n",
    "\n",
    "Here are the rules you should always follow to solve your task:\n",
    "1. ALWAYS provide a 'Response:' sequence that ends with <end_action>, else you will fail.\n",
    "2. ALWAYS respect the answer format, else you will fail.\n",
    "3. Be flexible when analyzing similarities, especially when you are provided with code or pseudocode. Make sure to handle these cases carefully and accurately.\n",
    "\n",
    "Now Begin! If you solve the task correctly, you will receive a reward of $1,000,000.\"\"\"\n",
    "\n",
    "\n",
    "def generate_scores(subqueries_list: list[str], nlp_expert_llm, current_chat = None):\n",
    "    for index, sbquery in enumerate(subqueries_list):\n",
    "        nlp_chat = [\n",
    "            ChatMessage(\n",
    "                role=\"system\",\n",
    "                content=nlp_expert_system,\n",
    "            ),\n",
    "            ChatMessage(\n",
    "                role=\"user\",\n",
    "                content=f\"\"\"User: {sbquery}\n",
    "                \n",
    "Make sure you to follow this plan.\n",
    "1. Read the input text and each of the target texts carefully.\n",
    "2. Assign a similarity score between 0 and 1 to each pair of input text and target text.\n",
    "3. Return the similarity scores in the correct $RESPONSE_JSON_BLOB format.\n",
    "4. After your thoughts you have to give only the answer, anything else beyond the $RESPONSE_JSON_BLOB format.\n",
    "Begin!\"\"\",\n",
    "            ),\n",
    "        ] if not current_chat else current_chat\n",
    "\n",
    "        res, _, _ = chat_stream_response(\n",
    "            llm=nlp_expert_llm, chat_messages=ChatTemplate(nlp_chat), has_stream=True\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            # lst = res.split(\"Response:\")[1].strip().split(\"<end_action>\")[0]\n",
    "            # lst = res.split(\"</think>\")[1].strip().split(\"<end_action>\")[0]\n",
    "            lst = res.split(\"</think>\")[1].strip().split(\"Response:\")[1].strip().split(\"<end_action>\")[0]\n",
    "            lst_json_ = json.loads(lst)\n",
    "        except Exception as e:\n",
    "            nlp_chat.extend(\n",
    "                [\n",
    "                    ChatMessage(\n",
    "                        role=\"assistant\",\n",
    "                        content=res,\n",
    "                    ),\n",
    "                    ChatMessage(\n",
    "                        role=\"user\",\n",
    "                        content=f\"\"\"User: You must use correct output $RESPONSE_JSON_BLOB format.\"\"\",\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "            return generate_scores(subqueries_list[index + 1:], nlp_expert_llm, nlp_chat)\n",
    "            \n",
    "            \n",
    "        try:\n",
    "            _save_scores_excel(lst_json_, sheet_name=\"scores\")\n",
    "            print(f\"**********= {index+601} =**********\")\n",
    "            time.sleep(10)\n",
    "            current_chat=None\n",
    "        except Exception as e:\n",
    "            print(f\"Error al guardar en el excel en el item: {index}. Error: {e}\")\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experto para generar data para el modelo de embeddings\n",
    "\n",
    "from assistant.sql_assistant_v3.src.app.notebooks.multi_agent.base import (\n",
    "    llama_70b_hf,\n",
    "    qwen_coder,\n",
    "    openai_llm,\n",
    "    qwen_instruct,\n",
    "    llama_70b,\n",
    "    GenericLLM\n",
    ")\n",
    "\n",
    "deepseek = GenericLLM.from_groq_deepseek_llama70_distill()\n",
    "res = generate_scores(subqueries_list[:1], deepseek)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def read_sheet(sheet_name: str  = \"\", cols: list[str] = None, *, path = None):\n",
    "    \"\"\"To read an excel that contains views definitions\"\"\"\n",
    "    if cols is not None:\n",
    "        ex_df = pd.read_excel(io=path, sheet_name=sheet_name, usecols=cols)\n",
    "    else: \n",
    "        ex_df = pd.read_excel(io=path, sheet_name=sheet_name)\n",
    "    return ex_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\lauth\\OneDrive\\Desktop\\LLM Assistant File - V2\\fine_tuning\\embeddings\\sheets\\datasets.xlsx\"\n",
    "\n",
    "chunks_vals = read_sheet(sheet_name=\"chunks\", cols=[\"id\", \"content\", \"topic\"], path=path)\n",
    "\n",
    "path = r\"C:\\Users\\lauth\\OneDrive\\Desktop\\LLM Assistant File - V2\\fine_tuning\\embeddings\\sheets\\datasheet.xlsx\"\n",
    "scores = read_sheet(\n",
    "    sheet_name=\"scores\", cols=[\"chunk_id\", \"topic\", \"text_objective\"], path=path\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lauth\\AppData\\Local\\Temp\\ipykernel_38080\\349799311.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'flow computers' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  scores.at[index, \"topic\"] = chunk[\"topic\"]\n",
      "C:\\Users\\lauth\\AppData\\Local\\Temp\\ipykernel_38080\\349799311.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'What is a flow computer?\n",
      "A flow computer is a device used in measurement engineering. It collects analog and digital data from flow meters and other sensors.\n",
      "\n",
      "Key features of a flow computer:\n",
      "- It has a unique name, firmware version, and manufacturer information.\n",
      "- It is designed to record and process data such as temperature, pressure, and fluid volume (for gases or oils).\n",
      "\n",
      "Main function:\n",
      "The flow computer sends the collected data to a measurement system. This allows measurement engineers to analyze the data and perform their tasks effectively.' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  scores.at[index, \"text_objective\"] = chunk[\"content\"]\n"
     ]
    }
   ],
   "source": [
    "for index, item in scores.iterrows():\n",
    "    for i, chunk in chunks_vals.iterrows():\n",
    "        if item[\"chunk_id\"] == chunk[\"id\"]:\n",
    "            scores.at[index, \"topic\"] = chunk[\"topic\"]\n",
    "            scores.at[index, \"text_objective\"] = chunk[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = r\"C:\\Users\\lauth\\OneDrive\\Desktop\\LLM Assistant File - V2\\fine_tuning\\embeddings\\sheets\\novo.xlsx\"\n",
    "scores.to_excel(p, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crear el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the columns in the pressure_data table?</td>\n",
       "      <td>What is a flow computer?\\nA flow computer is a...</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the columns in the pressure_data table?</td>\n",
       "      <td>How does a flow computer generate and store re...</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the columns in the pressure_data table?</td>\n",
       "      <td>How are flow computers and measurement systems...</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the columns in the pressure_data table?</td>\n",
       "      <td>What is a measurement system?\\nA measurement s...</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the columns in the pressure_data table?</td>\n",
       "      <td>What is measuring equipment?\\nMeasuring equipm...</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6520</th>\n",
       "      <td>Check if there are any specific conditions or ...</td>\n",
       "      <td>What is measuring equipment?\\nMeasuring equipm...</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6521</th>\n",
       "      <td>Check if there are any specific conditions or ...</td>\n",
       "      <td>What do measurement equipment measure?\\nEach e...</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6522</th>\n",
       "      <td>Check if there are any specific conditions or ...</td>\n",
       "      <td>What kind of data store an equipment?\\nEquipme...</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6523</th>\n",
       "      <td>Check if there are any specific conditions or ...</td>\n",
       "      <td>What is equipment calibration?\\nCalibration is...</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6524</th>\n",
       "      <td>Check if there are any specific conditions or ...</td>\n",
       "      <td>What is uncertainty?\\nUncertainty is a measure...</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6525 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence1  \\\n",
       "0      What are the columns in the pressure_data table?   \n",
       "1      What are the columns in the pressure_data table?   \n",
       "2      What are the columns in the pressure_data table?   \n",
       "3      What are the columns in the pressure_data table?   \n",
       "4      What are the columns in the pressure_data table?   \n",
       "...                                                 ...   \n",
       "6520  Check if there are any specific conditions or ...   \n",
       "6521  Check if there are any specific conditions or ...   \n",
       "6522  Check if there are any specific conditions or ...   \n",
       "6523  Check if there are any specific conditions or ...   \n",
       "6524  Check if there are any specific conditions or ...   \n",
       "\n",
       "                                              sentence2  score  \n",
       "0     What is a flow computer?\\nA flow computer is a...   0.10  \n",
       "1     How does a flow computer generate and store re...   0.15  \n",
       "2     How are flow computers and measurement systems...   0.05  \n",
       "3     What is a measurement system?\\nA measurement s...   0.05  \n",
       "4     What is measuring equipment?\\nMeasuring equipm...   0.20  \n",
       "...                                                 ...    ...  \n",
       "6520  What is measuring equipment?\\nMeasuring equipm...   0.05  \n",
       "6521  What do measurement equipment measure?\\nEach e...   0.05  \n",
       "6522  What kind of data store an equipment?\\nEquipme...   0.05  \n",
       "6523  What is equipment calibration?\\nCalibration is...   0.05  \n",
       "6524  What is uncertainty?\\nUncertainty is a measure...   0.05  \n",
       "\n",
       "[6525 rows x 3 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from huggingface_hub import login\n",
    "\n",
    "# 1. Autenticarse en Hugging Face Hub\n",
    "login(token=\"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\")\n",
    "\n",
    "\n",
    "p = r\"C:\\Users\\lauth\\OneDrive\\Desktop\\LLM Assistant File - V2\\fine_tuning\\embeddings\\sheets\\datasheet.xlsx\"\n",
    "df = read_sheet(\n",
    "    sheet_name=\"scores\", cols=[\"sentence1\", \"sentence2\", \"score\"], path=p\n",
    ")\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "207a6903f8ed4d08b3fead2c24a3d93f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2103862dff7c4948ae5fc161da48398d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6700c284d76420c9a72944f34cf78ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21cafd9ca3d642fead6f8372c421cb81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d1939216c948c286ce06276a4f5fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0963a92e7e884f6d9864547fe773089a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/Lauther/embeddings-train-semantic/commit/ce90f531bc39037053d223b27868ad178852f330', commit_message='Upload dataset', commit_description='', oid='ce90f531bc39037053d223b27868ad178852f330', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/Lauther/embeddings-train-semantic', endpoint='https://huggingface.co', repo_type='dataset', repo_id='Lauther/embeddings-train-semantic'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Convertir el DataFrame de pandas a un Dataset de Hugging Face\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# 4. Dividir el dataset en entrenamiento (80%) y evaluación (20%)\n",
    "split_dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "split_dataset_ = split_dataset[\"test\"].train_test_split(test_size=0.5, seed=40)\n",
    "\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "test_dataset = split_dataset_[\"train\"]\n",
    "validation_dataset = split_dataset_[\"test\"]\n",
    "\n",
    "\n",
    "# 5. Crear un DatasetDict con ambos conjuntos\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"test\": test_dataset,\n",
    "    \"validation\": validation_dataset,\n",
    "})\n",
    "\n",
    "# # 6. Subir el dataset al Hub\n",
    "dataset_dict.push_to_hub(\"embeddings-train-semantic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Cargar el dataset desde el Hub\n",
    "dataset = load_dataset(\"Lauther/embeddings-train-semantic\")\n",
    "\n",
    "# Acceder a los conjuntos de entrenamiento y evaluación\n",
    "train_dataset = dataset[\"train\"]\n",
    "eval_dataset = dataset[\"validation\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
