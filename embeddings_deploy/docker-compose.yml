services:
  vllm_embed:
    image: 0a4e266f3780
    container_name: vllm_embed
    ports:
      - "8000:8000"
    command: ["vllm", "serve", "Lauther/measuring-embeddings-v3", "--dtype", "auto", "--task", "embed", "--max-num-batched-tokens", "700", "--port", "8000"]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: always
    volumes:
      - /home/azureuser/projects/deploy/embeddings_deploy/models:/root/.cache/huggingface
      - ./logs:/app/logs
      - /dev/shm:/dev/shm
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3" 
